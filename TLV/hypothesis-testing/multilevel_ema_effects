import pandas as pd
import numpy as np
from pathlib import Path
import statsmodels.api as sm
import statsmodels.formula.api as smf
from scipy import stats
import logging
from datetime import datetime

class FragmentationAnalysis:
    def __init__(self, input_path: str, output_dir: str):
        self.input_path = Path(input_path)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self._setup_logging()
        self.within_results = []
        self.between_results = []
        
    def _setup_logging(self):
        log_path = self.output_dir / 'analysis.log'
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_path),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)

    def load_and_preprocess_data(self):
        self.logger.info("Loading data from %s", self.input_path)
        df = pd.read_csv(self.input_path)
        
        self.logger.info("\nMissing values before cleaning:")
        for col in df.columns:
            missing = df[col].isna().sum()
            if missing > 0:
                self.logger.info(f"{col}: {missing} missing values")
        
        key_vars = [
            'digital_frag_during_mobility', 'moving_fragmentation_index',
            'digital_fragmentation_index', 'total_time_on_device',
            'total_duration_mobility'
        ]
        df_clean = df.dropna(subset=key_vars)
        
        self.logger.info(f"\nObservations after cleaning: {len(df_clean)}")
        self.data = df_clean
        return df_clean

    def prepare_within_between_data(self, data, var):
        participant_means = data.groupby('participant_id')[var].transform('mean')
        within_var = data[var] - participant_means
        between_var = participant_means - participant_means.mean()
        return within_var, between_var

    def calculate_p_value(self, coef, std_err, df):
        t_stat = coef / std_err
        p_val = 2 * (1 - stats.t.cdf(abs(t_stat), df=df))
        return t_stat, p_val

    def run_mixed_effects_analysis(self):
        dependent_vars = [
            'TENSE', 'RELAXATION_R', 'WORRY', 'PEACE_R', 
            'IRRITATION', 'SATISFACTION_R', 'STAI6_score', 'HAPPY'
        ]
        
        independent_vars = [
            'digital_frag_during_mobility',
            'moving_fragmentation_index',
            'digital_fragmentation_index'
        ]
        
        control_vars = [
            'total_time_on_device',
            'total_duration_mobility'
        ]
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        for dep_var in dependent_vars:
            for indep_var in independent_vars:
                self.logger.info(f"Running analysis for {dep_var} ~ {indep_var}")
                
                analysis_vars = [dep_var, indep_var] + control_vars + ['participant_id']
                analysis_data = self.data[analysis_vars].dropna()
                
                if len(analysis_data) == 0:
                    self.logger.error(f"No complete cases for {dep_var} ~ {indep_var}")
                    continue
                
                # Compute within and between components
                for var in [indep_var] + control_vars:
                    within, between = self.prepare_within_between_data(analysis_data, var)
                    analysis_data[f'{var}_within'] = within
                    analysis_data[f'{var}_between'] = between
                
                # Separate formulas for within and between effects
                within_vars = [f'{var}_within' for var in [indep_var] + control_vars]
                between_vars = [f'{var}_between' for var in [indep_var] + control_vars]
                
                formula = (f"{dep_var} ~ {' + '.join(within_vars + between_vars)} + "
                         f"(1|participant_id)")
                
                try:
                    model = smf.mixedlm(formula, data=analysis_data, groups='participant_id')
                    results = model.fit()
                    df_resid = len(analysis_data) - len(results.params)
                    
                    # Process results for main effects and covariates
                    def process_effects(var_list, is_within):
                        effects_dict = {}
                        suffix = '_within' if is_within else '_between'
                        
                        for var in var_list:
                            var_name = f'{var}{suffix}'
                            if var_name in results.params:
                                coef = results.params[var_name]
                                std_err = results.bse[var_name]
                                t_stat, p_val = self.calculate_p_value(coef, std_err, df_resid)
                                ci_lower, ci_upper = results.conf_int().loc[var_name]
                                
                                effects_dict.update({
                                    f'coef_{var_name}': coef,
                                    f'std_err_{var_name}': std_err,
                                    f't_stat_{var_name}': t_stat,
                                    f'p_value_{var_name}': p_val,
                                    f'ci_lower_{var_name}': ci_lower,
                                    f'ci_upper_{var_name}': ci_upper
                                })
                        
                        return effects_dict
                    
                    # Process within-participant effects
                    within_effects = process_effects([indep_var] + control_vars, True)
                    # Process between-participant effects
                    between_effects = process_effects([indep_var] + control_vars, False)
                    
                    # Common model information
                    model_info = {
                        'dependent_var': dep_var,
                        'independent_var': indep_var,
                        'n_observations': len(analysis_data),
                        'n_participants': analysis_data['participant_id'].nunique(),
                        'aic': results.aic,
                        'bic': results.bic,
                        'coef_Intercept': results.params['Intercept']
                    }
                    
                    # Store within-participant results
                    self.within_results.append({
                        **model_info,
                        **within_effects,
                        'coefficient': within_effects[f'coef_{indep_var}_within'],
                        'std_error': within_effects[f'std_err_{indep_var}_within'],
                        't_statistic': within_effects[f't_stat_{indep_var}_within'],
                        'p_value': within_effects[f'p_value_{indep_var}_within'],
                        'ci_lower': within_effects[f'ci_lower_{indep_var}_within'],
                        'ci_upper': within_effects[f'ci_upper_{indep_var}_within']
                    })
                    
                    # Store between-participant results
                    self.between_results.append({
                        **model_info,
                        **between_effects,
                        'coefficient': between_effects[f'coef_{indep_var}_between'],
                        'std_error': between_effects[f'std_err_{indep_var}_between'],
                        't_statistic': between_effects[f't_stat_{indep_var}_between'],
                        'p_value': between_effects[f'p_value_{indep_var}_between'],
                        'ci_lower': between_effects[f'ci_lower_{indep_var}_between'],
                        'ci_upper': between_effects[f'ci_upper_{indep_var}_between']
                    })
                    
                    self.logger.info(f"Completed analysis for {dep_var} ~ {indep_var}")
                    
                except Exception as e:
                    self.logger.error(f"Error in analysis of {dep_var} ~ {indep_var}: {str(e)}")
        
        # Save results to CSV
        if self.within_results:
            within_df = pd.DataFrame(self.within_results)
            within_df = within_df.sort_values('p_value')
            within_csv_path = self.output_dir / f'within_participant_results_{timestamp}.csv'
            within_df.to_csv(within_csv_path, index=False)
            self.logger.info(f"Saved within-participant results to {within_csv_path}")
            
        if self.between_results:
            between_df = pd.DataFrame(self.between_results)
            between_df = between_df.sort_values('p_value')
            between_csv_path = self.output_dir / f'between_participant_results_{timestamp}.csv'
            between_df.to_csv(between_csv_path, index=False)
            self.logger.info(f"Saved between-participant results to {between_csv_path}")

def main():
    input_path = '/Users/noamgal/Downloads/Research-Projects/SURREAL/Amnon/metrics/prepared_metrics.csv'
    output_dir = '/Users/noamgal/Downloads/Research-Projects/SURREAL/Amnon/analysis_results'
    
    analyzer = FragmentationAnalysis(input_path, output_dir)
    analyzer.load_and_preprocess_data()
    analyzer.run_mixed_effects_analysis()
    
    print("Analysis completed successfully")

if __name__ == "__main__":
    main()