import pandas as pd
import numpy as np
from pathlib import Path
import statsmodels.api as sm
import statsmodels.formula.api as smf
from scipy import stats
import logging
from datetime import datetime

class FragmentationGroupAnalysis:
    def __init__(self, input_path: str, output_dir: str):
        self.input_path = Path(input_path)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self._setup_logging()
        self.comparison_results = []
        
    def _setup_logging(self):
        log_path = self.output_dir / 'group_analysis.log'
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_path),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)

    def load_data(self):
        """Load and perform basic preprocessing of the data"""
        self.logger.info(f"Loading data from {self.input_path}")
        self.data = pd.read_csv(self.input_path)
        return self.data

    def compare_groups(self):
        """Perform group comparisons for fragmentation metrics"""
        fragmentation_vars = [
            'digital_frag_during_mobility',
            'moving_fragmentation_index',
            'digital_fragmentation_index',
            'total_time_on_device'
        ]
        
        group_vars = ['Gender', 'School', 'is_weekend', 'Class']
        
        for frag_var in fragmentation_vars:
            self.logger.info(f"\nAnalyzing {frag_var}")
            
            for group_var in group_vars:
                try:
                    # Skip if too many missing values
                    if self.data[frag_var].isna().sum() / len(self.data) > 0.5:
                        self.logger.warning(f"Skipping {frag_var} due to too many missing values")
                        continue
                    
                    # Get groups
                    groups = self.data[group_var].unique()
                    
                    if len(groups) == 2:  # Binary comparison (Gender, School, is_weekend)
                        # Perform t-test
                        group1_data = self.data[self.data[group_var] == groups[0]][frag_var].dropna()
                        group2_data = self.data[self.data[group_var] == groups[1]][frag_var].dropna()
                        
                        t_stat, p_value = stats.ttest_ind(group1_data, group2_data)
                        
                        # Calculate effect size (Cohen's d)
                        n1, n2 = len(group1_data), len(group2_data)
                        var1, var2 = np.var(group1_data, ddof=1), np.var(group2_data, ddof=1)
                        pooled_se = np.sqrt(((n1 - 1) * var1 + (n2 - 1) * var2) / (n1 + n2 - 2))
                        cohens_d = (np.mean(group1_data) - np.mean(group2_data)) / pooled_se
                        
                        result = {
                            'metric': frag_var,
                            'group_variable': group_var,
                            'test_type': 't-test',
                            'group1': groups[0],
                            'group2': groups[1],
                            'group1_mean': np.mean(group1_data),
                            'group2_mean': np.mean(group2_data),
                            'group1_std': np.std(group1_data),
                            'group2_std': np.std(group2_data),
                            'statistic': t_stat,
                            'p_value': p_value,
                            'effect_size': cohens_d,
                            'group1_n': n1,
                            'group2_n': n2
                        }
                        
                    elif len(groups) > 2:  # For Class (3+ groups)
                        # Perform one-way ANOVA
                        group_data = [self.data[self.data[group_var] == g][frag_var].dropna() 
                                    for g in groups]
                        
                        f_stat, p_value = stats.f_oneway(*group_data)
                        
                        # Calculate effect size (eta-squared)
                        groups_concat = np.concatenate(group_data)
                        grand_mean = np.mean(groups_concat)
                        ss_total = np.sum((groups_concat - grand_mean) ** 2)
                        ss_between = np.sum([len(g) * (np.mean(g) - grand_mean) ** 2 for g in group_data])
                        eta_squared = ss_between / ss_total
                        
                        result = {
                            'metric': frag_var,
                            'group_variable': group_var,
                            'test_type': 'ANOVA',
                            'statistic': f_stat,
                            'p_value': p_value,
                            'effect_size': eta_squared
                        }
                        
                        # Add means and counts for each group
                        for i, g in enumerate(groups):
                            result[f'group{i+1}'] = g
                            result[f'group{i+1}_mean'] = np.mean(group_data[i])
                            result[f'group{i+1}_std'] = np.std(group_data[i])
                            result[f'group{i+1}_n'] = len(group_data[i])
                    
                    self.comparison_results.append(result)
                    
                except Exception as e:
                    self.logger.error(f"Error analyzing {frag_var} by {group_var}: {str(e)}")

    def save_results(self):
        """Save the comparison results to CSV"""
        if self.comparison_results:
            df_results = pd.DataFrame(self.comparison_results)
            
            # Sort by p-value
            df_results = df_results.sort_values('p_value')
            
            # Add multiple comparison correction
            df_results['p_value_bonferroni'] = np.minimum(
                df_results['p_value'] * len(df_results), 1.0
            )
            
            # Save to CSV
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_path = self.output_dir / f'group_comparisons_{timestamp}.csv'
            df_results.to_csv(output_path, index=False)
            
            self.logger.info(f"Saved group comparison results to {output_path}")

def main():
    input_path = '/Users/noamgal/Downloads/Research-Projects/SURREAL/Amnon/metrics/prepared_metrics.csv'
    output_dir = '/Users/noamgal/Downloads/Research-Projects/SURREAL/Amnon/analysis_results'
    
    analyzer = FragmentationGroupAnalysis(input_path, output_dir)
    analyzer.load_data()
    analyzer.compare_groups()
    analyzer.save_results()
    
    print("Group comparison analysis completed successfully")

if __name__ == "__main__":
    main()