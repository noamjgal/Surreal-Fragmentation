import pandas as pd
import numpy as np
from pathlib import Path
import statsmodels.api as sm
import statsmodels.formula.api as smf
from scipy import stats
import logging
from datetime import datetime

class FragmentationAnalysis:
    def __init__(self, input_path: str, output_dir: str):
        self.input_path = Path(input_path)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self._setup_logging()
        self.results_list = []  # Store all results for CSV
        
    def _setup_logging(self):
        log_path = self.output_dir / 'analysis.log'
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_path),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)

    def load_and_preprocess_data(self):
        self.logger.info("Loading data from %s", self.input_path)
        df = pd.read_csv(self.input_path)
        
        # Handle missing values
        self.logger.info("\nMissing values before cleaning:")
        for col in df.columns:
            missing = df[col].isna().sum()
            if missing > 0:
                self.logger.info(f"{col}: {missing} missing values")
        
        # Drop rows with missing values in key variables
        key_vars = [
            'digital_frag_during_mobility', 'moving_fragmentation_index',
            'digital_fragmentation_index', 'total_time_on_device',
            'total_duration_mobility'
        ]
        df_clean = df.dropna(subset=key_vars)
        
        self.logger.info(f"\nObservations after cleaning: {len(df_clean)}")
        self.data = df_clean
        return df_clean

    def run_mixed_effects_analysis(self):
        dependent_vars = [
            'TENSE', 'RELAXATION_R', 'WORRY', 'PEACE_R', 
            'IRRITATION', 'SATISFACTION_R', 'STAI6_score', 'HAPPY'
        ]
        
        independent_vars = [
            'digital_frag_during_mobility',
            'moving_fragmentation_index',
            'digital_fragmentation_index'
        ]
        
        control_vars = [
            'total_time_on_device',
            'total_duration_mobility'
        ]
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        for dep_var in dependent_vars:
            for indep_var in independent_vars:
                self.logger.info(f"Running analysis for {dep_var} ~ {indep_var}")
                
                # Create subset without missing values for this analysis
                analysis_vars = [dep_var, indep_var] + control_vars + ['participant_id']
                analysis_data = self.data[analysis_vars].dropna()
                
                if len(analysis_data) == 0:
                    self.logger.error(f"No complete cases for {dep_var} ~ {indep_var}")
                    continue
                
                formula = (f"{dep_var} ~ {indep_var} + {' + '.join(control_vars)} + "
                         f"(1|participant_id)")
                
                try:
                    model = smf.mixedlm(
                        formula,
                        data=analysis_data,
                        groups='participant_id'
                    )
                    
                    results = model.fit()
                    
                    # Extract key statistics for CSV
                    coef = results.params[indep_var]
                    std_err = results.bse[indep_var]
                    t_stat = coef / std_err
                    p_val = 2 * (1 - stats.t.cdf(abs(t_stat), df=len(analysis_data)-len(results.params)))
                    ci_lower, ci_upper = results.conf_int().loc[indep_var]
                    
                    # Store results
                    self.results_list.append({
                        'dependent_var': dep_var,
                        'independent_var': indep_var,
                        'coefficient': coef,
                        'std_error': std_err,
                        't_statistic': t_stat,
                        'p_value': p_val,
                        'ci_lower': ci_lower,
                        'ci_upper': ci_upper,
                        'n_observations': len(analysis_data),
                        'n_participants': analysis_data['participant_id'].nunique(),
                        'aic': results.aic,
                        'bic': results.bic
                    })
                    
                    self.logger.info(f"Completed analysis for {dep_var} ~ {indep_var}")
                    
                except Exception as e:
                    self.logger.error(f"Error in analysis of {dep_var} ~ {indep_var}: {str(e)}")
        
        # Save results to CSV
        if self.results_list:
            results_df = pd.DataFrame(self.results_list)
            # Sort by p-value ascending
            results_df = results_df.sort_values('p_value')
            # Save to CSV
            csv_path = self.output_dir / f'analysis_results_{timestamp}.csv'
            results_df.to_csv(csv_path, index=False)
            self.logger.info(f"Saved results to {csv_path}")

def main():
    input_path = '/Users/noamgal/Downloads/Research-Projects/SURREAL/Amnon/metrics/prepared_metrics.csv'
    output_dir = '/Users/noamgal/Downloads/Research-Projects/SURREAL/Amnon/analysis_results'
    
    analyzer = FragmentationAnalysis(input_path, output_dir)
    analyzer.load_and_preprocess_data()
    analyzer.run_mixed_effects_analysis()
    
    print("Analysis completed successfully")

if __name__ == "__main__":
    main()